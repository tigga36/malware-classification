{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8yBTc9guS2C7"
   },
   "source": [
    "# CNN Classification Against Malware Doc2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xTEFH4L8Xl8p"
   },
   "source": [
    "***Disclaimer:*** This notebook was imported from Google Colaboratory, and is not guarenteed to work in Jupyter Notebook. The Dropbox API was used for data I/O, but code related to keys linked directly to the project member's account have been removed for demonstration.\n",
    "\n",
    "This notebook shows how a CNN network was trained for a given string set, and serves the purpose of displaying the code that was necessary to obtain the results displayed on paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uX-2E1I6S9sI"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_X-n1BTmSzBm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import collections\n",
    "from random import randrange\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "import glob\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, BatchNormalization, Activation, Add, MaxPool1D, GlobalMaxPool1D, Dropout\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9BSn18YXBWC"
   },
   "outputs": [],
   "source": [
    "def read_json_contents(file_loc, first_n=-1):\n",
    "    package = []\n",
    "    dataDir = file_loc\n",
    "    files = sorted(glob.glob(dataDir+\"*.json\"))\n",
    "    for f in files[:first_n]:\n",
    "        read_file = open(f)\n",
    "        package.append(json.load(read_file)['strings'])\n",
    "    \n",
    "    return package\n",
    "\n",
    "def train_and_save_d2v_model_def_par(doc_set, name_of_model='my_doc2vec_model', vec_size=400):\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(doc_set)]\n",
    "    model = Doc2Vec(documents, vector_size=vec_size, window=2, min_count=1, workers=4)\n",
    "    fname = get_tmpfile(name_of_model)\n",
    "    model.save(fname)\n",
    "    model = Doc2Vec.load(fname)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_save_d2v_model(doc_set, name_of_model='my_doc2vec_model', vec_size=400):\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(doc_set)]\n",
    "    model = Doc2Vec(documents, vector_size=vec_size, window=1, min_count=2, workers=4)\n",
    "    fname = get_tmpfile(name_of_model)\n",
    "    model.save(fname)\n",
    "    model = Doc2Vec.load(fname)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def construct_feature_vector_set(vec_set, model, is_positive_set):\n",
    "    X_raw = []\n",
    "    for vec in vec_set:\n",
    "        X_raw.append(model.infer_vector(vec))\n",
    "    \n",
    "    if(is_positive_set):\n",
    "        y = np.array([0.]*len(vec_set))\n",
    "    else:\n",
    "        y = np.array([1.]*len(vec_set))\n",
    "\n",
    "    return np.array(X_raw), y\n",
    "\n",
    "def train_svm_class(train_data, train_label):\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto', probability=True))\n",
    "    clf.fit(train_data, train_label)\n",
    "    return clf\n",
    "\n",
    "def print_roc(clf, X, y):\n",
    "    y_score = clf.decision_function(X)\n",
    "    fpr, tpr, _ = roc_curve(y, clf.predict_proba(X)[:,1], pos_label=clf.classes_[1])\n",
    "    print('AUC: ', sklearn.metrics.auc(fpr, tpr))\n",
    "    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4d29piJ3qeG"
   },
   "source": [
    "### Data Packaging for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "Z2rygdyu3wL9",
    "outputId": "16900047-baa3-4e9f-8239-a0a8de1236c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "ffri_loc = 'strings_v5/new_FFRI_strings/'\n",
    "cnet_loc = 'strings_v5/new_Cnet_strings/'\n",
    "\n",
    "# pos_data = read_json_contents(ffri_loc+'ffri_2013_strings/') + read_json_contents(ffri_loc+'ffri_2014_strings/')\n",
    "# fal_data = read_json_contents(cnet_loc+'CnetA/')\n",
    "pos_test_data_all = read_json_contents(ffri_loc+'ffri_2015_strings/') + read_json_contents(ffri_loc+'ffri_2016_strings/') + read_json_contents(ffri_loc+'ffri_2017_strings/')\n",
    "# fal_test_data = read_json_contents(cnet_loc+'CnetB/')\n",
    "\n",
    "pos_data = read_json_contents(ffri_loc + 'ffri_2013_strings/') + read_json_contents(ffri_loc + 'ffri_2014_strings/')\n",
    "fal_data = read_json_contents(cnet_loc + 'CnetA/')\n",
    "pos_test_data_15 = read_json_contents(ffri_loc + 'ffri_2015_strings/')\n",
    "pos_test_data_16 = read_json_contents(ffri_loc + 'ffri_2016_strings/')\n",
    "pos_test_data_17 = read_json_contents(ffri_loc + 'ffri_2017_strings/')\n",
    "fal_test_data = read_json_contents(cnet_loc + 'CnetB/')\n",
    "\n",
    "model_train = train_and_save_d2v_model(pos_data+fal_data)\n",
    "\n",
    "# X_pos, y_pos = construct_feature_vector_set(pos_data, model_train, True)\n",
    "# X_fal, y_fal = construct_feature_vector_set(fal_data, model_train, False)\n",
    "X_test_pos, y_test_pos = construct_feature_vector_set(pos_test_data_all, model_train, True)\n",
    "X_test_fal, y_test_fal = construct_feature_vector_set(fal_test_data, model_train, False)\n",
    "\n",
    "# X_train = np.append(X_pos,X_fal, axis=0)\n",
    "# y_train = np.append(y_pos,y_fal)\n",
    "X_test = np.append(X_test_pos,X_test_fal, axis=0)\n",
    "y_test = np.append(y_test_pos,y_test_fal)\n",
    "\n",
    "X_pos, y_pos = construct_feature_vector_set(pos_data, model_train, True)\n",
    "X_fal, y_fal = construct_feature_vector_set(fal_data, model_train, False)\n",
    "X_test_pos_15, y_test_pos_15 = construct_feature_vector_set(pos_test_data_15, model_train, True)\n",
    "X_test_pos_16, y_test_pos_16 = construct_feature_vector_set(pos_test_data_16, model_train, True)\n",
    "X_test_pos_17, y_test_pos_17 = construct_feature_vector_set(pos_test_data_17, model_train, True)\n",
    "X_test_fal, y_test_fal = construct_feature_vector_set(fal_test_data, model_train, False)\n",
    "\n",
    "X_train = np.append(X_pos,X_fal, axis=0)\n",
    "y_train = np.append(y_pos,y_fal)\n",
    "X_test_15 = np.append(X_test_pos_15,X_test_fal, axis=0)\n",
    "y_test_15 = np.append(y_test_pos_15,y_test_fal)\n",
    "X_test_16 = np.append(X_test_pos_16,X_test_fal, axis=0)\n",
    "y_test_16 = np.append(y_test_pos_16,y_test_fal)\n",
    "X_test_17 = np.append(X_test_pos_17,X_test_fal, axis=0)\n",
    "y_test_17 = np.append(y_test_pos_17,y_test_fal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdxslUrW4gK4"
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((\n",
    "\t\ttf.cast(X_train, tf.float32),\n",
    "\t\ttf.cast(pd.get_dummies(y_train).values, tf.float32)\n",
    "\t\t))\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices((\n",
    "\t\ttf.cast(X_test, tf.float32),\n",
    "\t\ttf.cast(pd.get_dummies(y_test).values, tf.float32)\n",
    "\t\t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3mlgfqoTS_Xj"
   },
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mptnggEMTB_6"
   },
   "outputs": [],
   "source": [
    "# TODO: If using ResNet architecture (CNN), implement ResBlock class for a reusable and modular component\n",
    "\n",
    "class malware_classifier(Model):\n",
    "  def __init__(self):\n",
    "    self._optimizer = tf.optimizers.Adam() # Adam Optimizer for now\n",
    "    super(malware_classifier, self).__init__()\n",
    "\n",
    "    self._layers = [\n",
    "      # Flatten(), # Flattening function if need be, in case feature vector has dimension > 1\n",
    "      # Just dense layers for now\n",
    "      # How many filters?\n",
    "      Conv1D(50, 5, padding=\"same\"),\n",
    "      Activation(tf.nn.relu),\n",
    "      BatchNormalization(),\n",
    "      MaxPool1D(10, 2, padding=\"same\"),\n",
    "      Flatten(),\n",
    "      Dense(50, activation='relu'),\n",
    "      Dropout(0.5),\n",
    "      Dense(10, activation='relu'),\n",
    "      Dense(2, activation='softmax'), # Binary Logit\n",
    "    ]\n",
    "    \n",
    "    # self._layers = [\n",
    "    #   # Flatten(), # Flattening function if need be, in case feature vector has dimension > 1\n",
    "    #   # Just dense layers for now\n",
    "    #   # How many filters?\n",
    "    #   Conv1D(50, 5, padding=\"same\"),\n",
    "    #   Activation(tf.nn.relu),\n",
    "    #   BatchNormalization(),\n",
    "    #   GlobalMaxPool1D(),\n",
    "    #   Dense(50, activation='relu'),\n",
    "    #   Dropout(0.5),\n",
    "    #   Dense(10, activation='relu'),\n",
    "    #   Dense(2, activation='softmax'), # Binary Logit\n",
    "    # ]\n",
    "\n",
    "  @tf.function\n",
    "  def call(self, x):\n",
    "    x = x[..., tf.newaxis]\n",
    "    for layer in self._layers:\n",
    "        if isinstance(layer, list):\n",
    "            for l in layer:\n",
    "                x = l(x) \n",
    "                # print(x)   \n",
    "        else:\n",
    "            x = layer(x)\n",
    "            # print(x)   \n",
    "    return x\n",
    "\n",
    "  @tf.function\n",
    "  def loss(self, data, labels):\n",
    "    loss_object =  tf.keras.losses.CategoricalCrossentropy()\n",
    "    predictions = self.call(data)\n",
    "    return loss_object(labels, predictions)\n",
    "\n",
    "  @tf.function\n",
    "  def accuracy(self, data, labels):\n",
    "    classification_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    predictions = self.call(data)\n",
    "    # print(precision_recall_fscore_support(tf.math.argmax(labels, -1), tf.math.argmax(predictions, -1), average='macro'))\n",
    "    return classification_accuracy(labels, predictions)\n",
    "\n",
    "  @tf.function\n",
    "  def train(self, data, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "      loss = self.loss(data, labels)\n",
    "      acc = self.accuracy(data, labels)\n",
    "    grads = tape.gradient(loss, self.trainable_variables)\n",
    "    self._optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "    return {'training-loss': loss, 'training-acc': acc}\n",
    "\n",
    "  @tf.function\n",
    "  def evaluate(self, data, labels):\n",
    "    loss = self.loss(data, labels)\n",
    "    acc = self.accuracy(data, labels)\n",
    "    return {'test-loss': loss, 'test-acc': acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "W5WZ5Iun-8E_",
    "outputId": "a7e6de31-067f-4f77-bc16-6fe5b4c729be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.48932475, 0.51067525]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = malware_classifier()\n",
    "model.call(tf.convert_to_tensor(np.ones(400), tf.float32)[tf.newaxis, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZT0UxMBoTG9v"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wXiQ9Aa6TH0y",
    "outputId": "c7e90392-2b9a-4676-e6b2-3e849cffe152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Creating Directory \"/nlp-malware-classifier/models/final_3_v5\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/checkpoint\" to \"/nlp-malware-classifier/models/final_3_v5/checkpoint\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.data-00000-of-00001\" to \"/nlp-malware-classifier/models/final_3_v5/model-epoch-1-acc-0.77099234.data-00000-of-00001\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.index\" to \"/nlp-malware-classifier/models/final_3_v5/model-epoch-1-acc-0.77099234.index\"... DONE\n",
      "Epoch 1\n",
      "Train: training-loss 0.56, training-acc 0.70\n",
      "Val:  test-loss 0.56, test-acc 0.73\n",
      " > Creating Directory \"/nlp-malware-classifier/models/final_3_v5/final_3_v5\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/checkpoint\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/checkpoint\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.data-00000-of-00001\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-1-acc-0.77099234.data-00000-of-00001\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.index\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-1-acc-0.77099234.index\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.data-00000-of-00001\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-2-acc-0.79770994.data-00000-of-00001\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.index\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-2-acc-0.79770994.index\"... DONE\n",
      "Epoch 2\n",
      "Train: training-loss 0.36, training-acc 0.85\n",
      "Val:  test-loss 0.55, test-acc 0.75\n",
      " > Creating Directory \"/nlp-malware-classifier/models/final_3_v5/final_3_v5\"... FAILED\n",
      " > Uploading \"/content/models/final_3_v5/checkpoint\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/checkpoint\"... DONE\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.index\", file exists with the same hash\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.data-00000-of-00001\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-3-acc-0.79389316.data-00000-of-00001\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.index\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-3-acc-0.79389316.index\"... DONE\n",
      "Some error occured. Please check the log.\n",
      "Epoch 3\n",
      "Train: training-loss 0.28, training-acc 0.89\n",
      "Val:  test-loss 0.70, test-acc 0.72\n",
      " > Creating Directory \"/nlp-malware-classifier/models/final_3_v5/final_3_v5\"... FAILED\n",
      " > Uploading \"/content/models/final_3_v5/checkpoint\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/checkpoint\"... DONE\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.index\", file exists with the same hash\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.data-00000-of-00001\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-4-acc-0.7366412.data-00000-of-00001\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.index\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-4-acc-0.7366412.index\"... DONE\n",
      "Some error occured. Please check the log.\n",
      "Epoch 4\n",
      "Train: training-loss 0.24, training-acc 0.91\n",
      "Val:  test-loss 0.95, test-acc 0.69\n",
      " > Creating Directory \"/nlp-malware-classifier/models/final_3_v5/final_3_v5\"... FAILED\n",
      " > Uploading \"/content/models/final_3_v5/checkpoint\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/checkpoint\"... DONE\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.index\", file exists with the same hash\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-5-acc-0.78244275.data-00000-of-00001\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-5-acc-0.78244275.data-00000-of-00001\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-5-acc-0.78244275.index\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-5-acc-0.78244275.index\"... DONE\n",
      "Some error occured. Please check the log.\n",
      "Epoch 5\n",
      "Train: training-loss 0.20, training-acc 0.93\n",
      "Val:  test-loss 1.23, test-acc 0.66\n",
      " > Creating Directory \"/nlp-malware-classifier/models/final_3_v5/final_3_v5\"... FAILED\n",
      " > Uploading \"/content/models/final_3_v5/checkpoint\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/checkpoint\"... DONE\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-5-acc-0.78244275.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-5-acc-0.78244275.index\", file exists with the same hash\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-6-acc-0.72900766.data-00000-of-00001\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-6-acc-0.72900766.data-00000-of-00001\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-6-acc-0.72900766.index\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-6-acc-0.72900766.index\"... DONE\n",
      "Some error occured. Please check the log.\n",
      "Epoch 6\n",
      "Train: training-loss 0.19, training-acc 0.93\n",
      "Val:  test-loss 1.31, test-acc 0.66\n",
      " > Creating Directory \"/nlp-malware-classifier/models/final_3_v5/final_3_v5\"... FAILED\n",
      " > Uploading \"/content/models/final_3_v5/checkpoint\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/checkpoint\"... DONE\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-5-acc-0.78244275.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-5-acc-0.78244275.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-6-acc-0.72900766.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-6-acc-0.72900766.index\", file exists with the same hash\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-7-acc-0.7633588.data-00000-of-00001\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-7-acc-0.7633588.data-00000-of-00001\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-7-acc-0.7633588.index\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-7-acc-0.7633588.index\"... DONE\n",
      "Some error occured. Please check the log.\n",
      "Epoch 7\n",
      "Train: training-loss 0.16, training-acc 0.94\n",
      "Val:  test-loss 1.39, test-acc 0.64\n",
      " > Creating Directory \"/nlp-malware-classifier/models/final_3_v5/final_3_v5\"... FAILED\n",
      " > Uploading \"/content/models/final_3_v5/checkpoint\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/checkpoint\"... DONE\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-5-acc-0.78244275.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-5-acc-0.78244275.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-6-acc-0.72900766.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-6-acc-0.72900766.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-7-acc-0.7633588.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-7-acc-0.7633588.index\", file exists with the same hash\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-8-acc-0.7099237.data-00000-of-00001\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-8-acc-0.7099237.data-00000-of-00001\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-8-acc-0.7099237.index\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-8-acc-0.7099237.index\"... DONE\n",
      "Some error occured. Please check the log.\n",
      "Epoch 8\n",
      "Train: training-loss 0.15, training-acc 0.94\n",
      "Val:  test-loss 1.82, test-acc 0.61\n",
      " > Creating Directory \"/nlp-malware-classifier/models/final_3_v5/final_3_v5\"... FAILED\n",
      " > Uploading \"/content/models/final_3_v5/checkpoint\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/checkpoint\"... DONE\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-1-acc-0.77099234.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-2-acc-0.79770994.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-3-acc-0.79389316.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-4-acc-0.7366412.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-5-acc-0.78244275.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-5-acc-0.78244275.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-6-acc-0.72900766.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-6-acc-0.72900766.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-7-acc-0.7633588.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-7-acc-0.7633588.index\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-8-acc-0.7099237.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/content/models/final_3_v5/model-epoch-8-acc-0.7099237.index\", file exists with the same hash\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-9-acc-0.7251908.data-00000-of-00001\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-9-acc-0.7251908.data-00000-of-00001\"... DONE\n",
      " > Uploading \"/content/models/final_3_v5/model-epoch-9-acc-0.7251908.index\" to \"/nlp-malware-classifier/models/final_3_v5/final_3_v5/model-epoch-9-acc-0.7251908.index\"... DONE\n",
      "Some error occured. Please check the log.\n",
      "Epoch 9\n",
      "Train: training-loss 0.15, training-acc 0.94\n",
      "Val:  test-loss 1.97, test-acc 0.61\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-de9182fd1445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;31m# parser.add_argument('--learning_rate', type=float, default=1e-3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;31m# parser.add_argument('--decoder_std', type=float, default=0.1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-de9182fd1445>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;31m# Use eval method to get results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;31m# Parse results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mRUN_FUNCTIONS_EAGERLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_function_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3728\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m         \u001b[0mwrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unbound_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweak_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3732\u001b[0m     \u001b[0;31m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-2bc91151944d>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data, labels)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'test-loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test-acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mRUN_FUNCTIONS_EAGERLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_function_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3728\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m         \u001b[0mwrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unbound_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweak_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3732\u001b[0m     \u001b[0;31m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-2bc91151944d>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, data, labels)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mloss_object\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mRUN_FUNCTIONS_EAGERLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_function_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3728\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m         \u001b[0mwrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unbound_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweak_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3732\u001b[0m     \u001b[0;31m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-2bc91151944d>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;31m# print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;31m# print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1149\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)\u001b[0m\n\u001b[1;32m   1887\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1890\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m       result = squeeze_batch_dims(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m    936\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_classifier(args):\n",
    "  # Load training/validation feature vectors\n",
    "\n",
    "  # Make train and val sets using tf.data scheme\n",
    "  train = train_data.shuffle(10000).batch(500).prefetch(1)\n",
    "  val = test_data.shuffle(10000).batch(500).prefetch(1)\n",
    "\n",
    "  # Initialize model\n",
    "  model = malware_classifier()\n",
    "\n",
    "  # Train in epochs\n",
    "  for epoch in range(1, args.epochs + 1):\n",
    "    # Initialize list for metrics with dict\n",
    "    ms1 = collections.defaultdict(list)\n",
    "    # Iterate through train, as they are split in sizes of batches\n",
    "    for vector, label in train:\n",
    "      # Have the training method return metrics object attained during training\n",
    "      metrics = model.train(vector, label)\n",
    "      # Use dict comprehension to set values in dict\n",
    "      {ms1[key].append(value) for key, value in metrics.items()}\n",
    "    # Arbitrary conditional to check status\n",
    "    if epoch % args.eval_every != 0:\n",
    "      continue\n",
    "\n",
    "    # Dict setup for test evaluation results\n",
    "    ms2 = collections.defaultdict(list)\n",
    "\n",
    "    # Iterate through test\n",
    "    for vector, label in val:\n",
    "      # Use eval method to get results\n",
    "      metrics = model.evaluate(vector, label)\n",
    "\n",
    "      # Parse results\n",
    "      {ms2[key].append(value) for key, value in metrics.items()}\n",
    "\n",
    "    model.save_weights('./models/final_3_v5/model-epoch-'+str(epoch)+'-acc-'+str(metrics['test-acc'].numpy()))\n",
    "    ! Dropbox-Uploader/dropbox_uploader.sh upload ./models/final_3_v5 ./nlp-malware-classifier/models/final_3_v5\n",
    "\n",
    "    # Print stats\n",
    "    print('Epoch', epoch)\n",
    "    print('Train:', ', '.join(f'{k} {np.mean(v):.2f}' for k, v in ms1.items()))\n",
    "    print('Val: ', ', '.join(f'{k} {np.mean(v):.2f}' for k, v in ms2.items()))\n",
    "\n",
    "  y_res = model.call(X_test)\n",
    "  fpr, tpr, _ = roc_curve(y_test, y_res.numpy()[:,1], pos_label=1.0)\n",
    "  print('AUC: ', sklearn.metrics.auc(fpr, tpr))\n",
    "  print(precision_recall_fscore_support(y_test, tf.math.argmax(y_res, -1), average='macro'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('--epochs', type=int, default=30)\n",
    "  parser.add_argument('--eval_every', type=int, default=1)\n",
    "  # parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
    "  # parser.add_argument('--decoder_std', type=float, default=0.1)\n",
    "  train_classifier(parser.parse_args([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OhMyy46LTIuG"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "colab_type": "code",
    "id": "TRHvEy36Ebco",
    "outputId": "f8c00f6c-a48d-4118-a53d-ecc6dfa632fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading folder \"/nlp-malware-classifier/models/final_2_v1\" to \"/content/final_2_v1\"... \n",
      " > Downloading folder \"/nlp-malware-classifier/models/final_2_v1/final_2_v1\" to \"/content/final_2_v1/final_2_v1\"... \n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-1-acc-0.63740456.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-1-acc-0.63740456.index\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-2-acc-0.55725193.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-2-acc-0.55725193.index\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-3-acc-0.60305345.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-3-acc-0.60305345.index\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-4-acc-0.60687023.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-4-acc-0.60687023.index\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-5-acc-0.5801527.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-5-acc-0.5801527.index\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-1-acc-0.7900763.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-1-acc-0.7900763.index\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-2-acc-0.8244275.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-2-acc-0.8244275.index\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-3-acc-0.79389316.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-3-acc-0.79389316.index\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/checkpoint\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-4-acc-0.8129771.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/final_2_v1/model-epoch-4-acc-0.8129771.index\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/checkpoint\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/model-epoch-1-acc-0.63740456.data-00000-of-00001\", file exists with the same hash\n",
      "> Skipping file \"/nlp-malware-classifier/models/final_2_v1/model-epoch-1-acc-0.63740456.index\", file exists with the same hash\n"
     ]
    }
   ],
   "source": [
    "!Dropbox-Uploader/dropbox_uploader.sh download ./nlp-malware-classifier/models/final_2_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "stjIs8wJE8tL",
    "outputId": "a2c554b0-b0a7-41db-a4c1-07cbce7d1f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_3_v4\n"
     ]
    }
   ],
   "source": [
    "!ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "HTIRUh_1gM81",
    "outputId": "53d250cb-e0a4-4f13-f3cd-a58ad9f3d05d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFRI 2015:\n",
      "acc:  0.8178484107579462\n",
      "(0.7588323517406665, 0.7160292239936592, 0.7323462361776589, None)\n",
      "FFRI 2016:\n",
      "acc:  0.721806657911266\n",
      "(0.7579606354723463, 0.7097330218866559, 0.7037023341953642, None)\n",
      "FFRI 2017:\n",
      "acc:  0.774563494620192\n",
      "(0.7879532059296304, 0.74056975083594, 0.7490606416393605, None)\n"
     ]
    }
   ],
   "source": [
    "def eval():\n",
    "  model = malware_classifier()\n",
    "  model.load_weights('./models/final_3_v5/model-epoch-5-acc-0.78244275').expect_partial()\n",
    "  y_res_15 = tf.math.argmax(model.call(X_test_15), axis=1)\n",
    "  y_res_16 = tf.math.argmax(model.call(X_test_16), axis=1)\n",
    "  y_res_17 = tf.math.argmax(model.call(X_test_17), axis=1)\n",
    "\n",
    "  print('FFRI 2015:')\n",
    "  print('acc: ',sklearn.metrics.accuracy_score(y_test_15, y_res_15))\n",
    "  print(precision_recall_fscore_support(y_test_15, y_res_15, average='macro'))\n",
    "\n",
    "  print('FFRI 2016:')\n",
    "  print('acc: ',sklearn.metrics.accuracy_score(y_test_16, y_res_16))\n",
    "  print(precision_recall_fscore_support(y_test_16, y_res_16, average='macro'))\n",
    "\n",
    "  print('FFRI 2017:')\n",
    "  print('acc: ',sklearn.metrics.accuracy_score(y_test_17, y_res_17))\n",
    "  print(precision_recall_fscore_support(y_test_17, y_res_17, average='macro'))\n",
    "\n",
    "eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouCUMe0bTJPT"
   },
   "outputs": [],
   "source": [
    " fpr, tpr, _ = roc_curve(y, clf.predict_proba(X)[:,1], pos_label=clf.classes_[1])\n",
    "print('AUC: ', sklearn.metrics.auc(fpr, tpr))\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "malware-classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
